l2 <- lapply(filenames, function(x) {
filename = paste0(directory, "/", x);
if (file.exists(filename)){
read_csv(filename);
} else {
loginfo(paste("The file", x, "does not exist on that directory. Ignore."));
NULL;
}
});
names(l2) <- names;
c(l1, l2);
}
output <- the_fast_reader_function()
library(tidyverse)
the_fast_reader_function <- function (directory = ".") {
names <- c("Appearances", "Batting", "Fielding", "Master", "Pitching");
filenames <- gsub("$", ".csv", names);
l1 <- list(Origin = directory);
l2 <- lapply(filenames, function(x) {
filename = paste0(directory, "/", x);
if (file.exists(filename)){
read_csv(filename);
} else {
loginfo(paste("The file", x, "does not exist on that directory. Ignore."));
NULL;
}
});
names(l2) <- names;
c(l1, l2);
}
output <- the_fast_reader_function()
View(output)
setwd("~/workspace/masters-deg")
output2 <- the_fast_reader_function("./drake-tests/starvz-reader")
View(output2)
library(drake)
parallel_reader_function <- function (directory = ".") {
reader_plan <- drake_plan(
strings_in_dots = literals,
appearances = file_in(paste0(directory,"/Appearances.csv")) %>% read_csv,
batting = file_in(paste0(directory,"/Batting.csv")) %>% read_csv,
fielding = file_in(paste0(directory,"/Fielding.csv")) %>% read_csv,
master = file_in(paste0(directory,"/Master.csv")) %>% read_csv,
pitching = file_in(paste0(directory,"/Pitching.csv")) %>% read_csv
)
clean(reader_plan)
make(reader_plan)
output_list <- list(
directory,
appearances,
batting,
fielding,
master,
pitching
)
}
output3 <- parallel_reader_function("./drake-tests/starvz-reader")
parallel_reader_function <- function (directory = ".") {
reader_plan <- drake_plan(
strings_in_dots = "literals",
appearances = file_in(paste0(directory,"/Appearances.csv")) %>% read_csv,
batting = file_in(paste0(directory,"/Batting.csv")) %>% read_csv,
fielding = file_in(paste0(directory,"/Fielding.csv")) %>% read_csv,
master = file_in(paste0(directory,"/Master.csv")) %>% read_csv,
pitching = file_in(paste0(directory,"/Pitching.csv")) %>% read_csv
)
clean(reader_plan)
make(reader_plan)
output_list <- list(
directory,
appearances,
batting,
fielding,
master,
pitching
)
}
output3 <- parallel_reader_function("./drake-tests/starvz-reader")
View(output3)
listNames <- c("Origin", "Appearances", "Batting", "Pitching", "Master", "Fielding")
names(output3)<-listNames
output3
View(output3)
output3$Origin
parallel_reader_function <- function (directory = ".") {
reader_plan <- drake_plan(
strings_in_dots = "literals",
appearances = file_in(paste0(directory,"/Appearances.csv")) %>% read_csv,
batting = file_in(paste0(directory,"/Batting.csv")) %>% read_csv,
fielding = file_in(paste0(directory,"/Fielding.csv")) %>% read_csv,
master = file_in(paste0(directory,"/Master.csv")) %>% read_csv,
pitching = file_in(paste0(directory,"/Pitching.csv")) %>% read_csv
)
clean(reader_plan)
make(reader_plan)
output_list <- list(
directory,
appearances,
batting,
fielding,
master,
pitching
)
names(output_list) <- c("Origin", "Appearances", "Batting", "Fielding", "Master", "Pitching")
output_list
}
output4 <- parallel_reader_function("./drake-tests/starvz-reader")
View(output4)
parallel_reader_function <- function (directory = ".") {
reader_plan <- drake_plan(
strings_in_dots = "literals",
appearances <- file_in(paste0(directory,"/Appearances.csv")) %>% read_csv,
batting <- file_in(paste0(directory,"/Batting.csv")) %>% read_csv,
fielding <- file_in(paste0(directory,"/Fielding.csv")) %>% read_csv,
master <- file_in(paste0(directory,"/Master.csv")) %>% read_csv,
pitching <- file_in(paste0(directory,"/Pitching.csv")) %>% read_csv
)
clean(reader_plan)
make(reader_plan)
output_list <- list(
directory,
appearances,
batting,
fielding,
master,
pitching
)
names(output_list) <- c("Origin", "Appearances", "Batting", "Fielding", "Master", "Pitching")
output_list
}
output5 <- parallel_reader_function("./drake-tests/starvz-reader")
appearances
View(output5)
parallel_reader_function <- function (directory = ".") {
reader_plan <- drake_plan(
strings_in_dots = "literals",
appearances = file_in(paste0(directory,"/Appearances.csv")) %>% read_csv,
batting = file_in(paste0(directory,"/Batting.csv")) %>% read_csv,
fielding = file_in(paste0(directory,"/Fielding.csv")) %>% read_csv,
master = file_in(paste0(directory,"/Master.csv")) %>% read_csv,
pitching = file_in(paste0(directory,"/Pitching.csv")) %>% read_csv
)
clean(reader_plan)
make(reader_plan)
output_list <- list(
directory,
appearances,
batting,
fielding,
master,
pitching
)
names(output_list) <- c("Origin", "Appearances", "Batting", "Fielding", "Master", "Pitching")
output_list
}
output5 <- parallel_reader_function("./drake-tests/starvz-reader")
names <- c("State", "Variable", "Link", "DAG", "Y", "ATree", "Gaps", "pmtool", "pmtool_states");
test <- c("origin", names)
View(output2)
phase1_plan <- drake_plan(
rawDfw = read_state_csv(input.application, states.fun, states.filter.strict, input.directory),
zero = read_zero(rawDfw),
normalizedDfw = normalize_dfw(rawDfw, zero, input.application, states.fun, outlier_definition),
highlightedDfw = hl_y_coordinates(normalizedDfw, input.directory),
dfa = atree_load(input.directory),
dfap = build_dfap(dfa),
dfw = join_dfw_dfap(highlightedDfw, dfap),
dfv = read_vars_set_new_zero(input.directory, zero),
dfl = read_links(input.directory, zero),
dfdag = read_dag(input.directory, dfw, dfl),
dfhie = hl_y_paje_tree(input.directory),
dpmtb = pmtools_bounds_csv_parser(input.directory),
dpmts = pmtools_states_csv_parser(input.directory, input.application, dfhie, dfw),
ddh = data_handles_csv_parser(input.directory),
dtasks = tasks_csv_parser(input.directory),
aggregatedData = aggregate_data(input.directory, dfw, dfv, dfl, dfdag, dfhie, dfa, dpmtb, dpmts, ddh, dtasks),
computedGaps = calculate_gaps(input.application, aggregatedData)
);
library(drake)
phase1_plan <- drake_plan(
rawDfw = read_state_csv(input.application, states.fun, states.filter.strict, input.directory),
zero = read_zero(rawDfw),
normalizedDfw = normalize_dfw(rawDfw, zero, input.application, states.fun, outlier_definition),
highlightedDfw = hl_y_coordinates(normalizedDfw, input.directory),
dfa = atree_load(input.directory),
dfap = build_dfap(dfa),
dfw = join_dfw_dfap(highlightedDfw, dfap),
dfv = read_vars_set_new_zero(input.directory, zero),
dfl = read_links(input.directory, zero),
dfdag = read_dag(input.directory, dfw, dfl),
dfhie = hl_y_paje_tree(input.directory),
dpmtb = pmtools_bounds_csv_parser(input.directory),
dpmts = pmtools_states_csv_parser(input.directory, input.application, dfhie, dfw),
ddh = data_handles_csv_parser(input.directory),
dtasks = tasks_csv_parser(input.directory),
aggregatedData = aggregate_data(input.directory, dfw, dfv, dfl, dfdag, dfhie, dfa, dpmtb, dpmts, ddh, dtasks),
computedGaps = calculate_gaps(input.application, aggregatedData)
);
plan_config <- drake_config(phase1_plan);
clean(plan_config);
make(phase1_plan);
vis_drake_graph(plan_config)
build_drake_graph(plan_config)
build_drake_graph(phase1_plan)
graph <- build_drake_graph(phase1_plan)
View(graph)
library(drake)
phase1_plan <- drake_plan(
rawDfw = read_state_csv(input.application, states.fun, states.filter.strict, input.directory),
zero = read_zero(rawDfw),
normalizedDfw = normalize_dfw(rawDfw, zero, input.application, states.fun, outlier_definition),
highlightedDfw = hl_y_coordinates(normalizedDfw, input.directory),
dfa = atree_load(input.directory),
dfap = build_dfap(dfa),
dfw = join_dfw_dfap(highlightedDfw, dfap),
dfv = read_vars_set_new_zero(input.directory, zero),
dfl = read_links(input.directory, zero),
dfdag = read_dag(input.directory, dfw, dfl),
dfhie = hl_y_paje_tree(input.directory),
dpmtb = pmtools_bounds_csv_parser(input.directory),
dpmts = pmtools_states_csv_parser(input.directory, input.application, dfhie, dfw),
ddh = data_handles_csv_parser(input.directory),
dtasks = tasks_csv_parser(input.directory),
aggregatedData = aggregate_data(input.directory, dfw, dfv, dfl, dfdag, dfhie, dfa, dpmtb, dpmts, ddh, dtasks),
computedGaps = calculate_gaps(input.application, aggregatedData)
);
plan_config <- drake_config(phase1_plan);
vis_drake_graph()
ls
library(data.table)
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F)
fred
View(fred)
class(fred)
library(readr)
csv <- read_csv('/home/alles/tmp/tiny-csvs/paje.state.csv',
trim_ws=TRUE,
col_types = cols(
Nature = col_character(),
ResourceId = col_character(),
Type = col_character(),
Start = col_double(),
End = col_double(),
Duration = col_double(),
Depth = col_double(),
Value = col_character(),
Size = col_character(),
Params = col_character(),
Footprint = col_character(),
Tag = col_character(),
JobId = col_character(),
GFlop = col_character(),
SubmitOrder = col_character(),
X = col_character(),
Y = col_character(),
Iteration = col_character(),
Subiteration = col_character()
));
csv
class(csv)
fred_tibble = as.tibble(fred)
library(dplyr)
fred_tibble = as.tibble(fred)
package(tibble)
library(tibble)
fred_tibble = as.tibble(fred)
fred_tibble
identical(csv, fred_tibble)
identical(fred, fred_tibble)
identical(fred, fred)
all.equal(csv, fred_tibble)
csv
fred_tibble
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F)
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F, colClasses=cols(
Nature = col_character(),
ResourceId = col_character(),
Type = col_character(),
Start = col_double(),
End = col_double(),
Duration = col_double(),
Depth = col_double(),
Value = col_character(),
Size = col_character(),
Params = col_character(),
Footprint = col_character(),
Tag = col_character(),
JobId = col_character(),
GFlop = col_character(),
SubmitOrder = col_character(),
X = col_character(),
Y = col_character(),
Iteration = col_character(),
Subiteration = col_character()
));
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F, colClasses=cols(
Nature = 'character',
ResourceId = 'character',
Type = col_character(),
Start = col_double(),
End = col_double(),
Duration = col_double(),
Depth = col_double(),
Value = col_character(),
Size = col_character(),
Params = col_character(),
Footprint = col_character(),
Tag = col_character(),
JobId = col_character(),
GFlop = col_character(),
SubmitOrder = col_character(),
X = col_character(),
Y = col_character(),
Iteration = col_character(),
Subiteration = col_character()
));
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F, colClasses=c(
Nature = 'character',
ResourceId = 'character',
Type = col_character(),
Start = col_double(),
End = col_double(),
Duration = col_double(),
Depth = col_double(),
Value = col_character(),
Size = col_character(),
Params = col_character(),
Footprint = col_character(),
Tag = col_character(),
JobId = col_character(),
GFlop = col_character(),
SubmitOrder = col_character(),
X = col_character(),
Y = col_character(),
Iteration = col_character(),
Subiteration = col_character()
));
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F, colClasses=c(
'character',
'character',
'character',
'double',
'double',
'double',
'double',
'character',
'character',
'character',
'character',
'character',
'character',
'character',
'character',
'character',
'character',
'character',
'character'
));
fred_tibble <- as.tibble(fred)
identical(csv, fred_tibble)
fred_tibble
csv
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F);
fred <- fread('/home/alles/tmp/tiny-csvs/paje.state.csv', sep=',', header=T, fill=T, data.table=F);
fred_tibble <- as.tibble(fred);
fred_tibble <- fred_tibble %>% mutate(
Nature = as.character(Nature),
ResourceId = as.character(ResourceId),
Type = as.character(Type),
Start = as.double(Start),
End = as.double(End),
Duration = as.double(Duration),
Depth = as.double(Depth),
Value = as.character(Value),
Size = as.character(Size),
Params = as.character(Params),
Footprint = as.character(Footprint),
Tag = as.character(Tag),
JobId = as.character(JobId),
GFlop = as.character(GFlop),
SubmitOrder = as.character(SubmitOrder),
X = as.character(X),
Y = as.character(Y),
Iteration = as.character(Iteration),
Subiteration = as.character(Subiteration));
fred_tibble
identical(csv, fred_tibble)
identical(csv, fred_tibble)
fred_tibble
fred_tibble
csv
setwd("~/workspace/hpc-containers/wscad/ondes3d/results")
list.files()
docker_results <- read_csv('./doe-results.csv');
library(tidyverse);
docker_results <- read_csv('./doe-results.csv');
View(docker_results)
docker_results <- read_csv('./doe-results.csv');
sing_native_results <- read_csv('./doe-results-sing-native.csv');
results <- bind_rows(sing_native_results, docker_results)
results <- results %>%
group_by(environment, parallelism) %>%
summarize(
samples = n(),
average = mean(time),
stdDeviation = sd(time),
stdError = 2*stdDeviation/sqrt(samples)
);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
scale_y_continuous(breaks=seq(0, 90, 10), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("Ondes3D ESSAI", subtitle = "50 timesteps") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("Ondes3D ESSAI", subtitle = "50 timesteps") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
results <- bind_rows(sing_native_results, docker_results)
results <- results %>%
mutate(time = time/1000) %>%
group_by(environment, parallelism) %>%
summarize(
samples = n(),
average = mean(time),
stdDeviation = sd(time),
stdError = 2*stdDeviation/sqrt(samples)
);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("Ondes3D ESSAI", subtitle = "50 timesteps") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
View(results)
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
scale_y_continuous(breaks=c(0, 32, 4), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("Ondes3D ESSAI", subtitle = "50 timesteps") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
scale_y_continuous(breaks=seq(0, 32, 4), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("Ondes3D ESSAI", subtitle = "50 timesteps") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
setwd("~/workspace/hpc-containers/wscad/ep/results")
docker_results <- read_csv('./ep-results.csv');
sing_native_results <- read_csv('./ep-sing-native-results.csv');
results <- bind_rows(sing_native_results, docker_results)
results <- results %>%
mutate(time=time/1000) %>%
group_by(environment, parallelism) %>%
summarize(
samples = n(),
average = mean(time),
stdDeviation = sd(time),
stdError = 2*stdDeviation/sqrt(samples)
);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
scale_y_continuous(breaks=seq(0, 90, 10), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("NAS EP Benchmark", subtitle = "Category B") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
docker_results <- read_csv('./ep-results.csv');
sing_native_results <- read_csv('./ep-sing-native-results.csv');
results <- bind_rows(sing_native_results, docker_results);
results <- results %>%
mutate(time=time/1000) %>%
group_by(environment, parallelism) %>%
summarize(
samples = n(),
average = mean(time),
stdDeviation = sd(time),
stdError = 2*stdDeviation/sqrt(samples)
);
g <- ggplot(results, aes(x = parallelism, y = average)) +
scale_x_continuous(breaks=c(1, 4, 8, 16), trans='sqrt') +
scale_y_continuous(breaks=seq(0, 90, 10), trans='sqrt') +
geom_point(aes(col=environment), size=2) +
geom_line(aes(col=environment), size = 0.5) +
geom_errorbar(aes(ymin=average-stdError, ymax=average+stdError, col=environment), width=0.5) +
ggtitle("NAS EP Benchmark", subtitle = "Category B") +
xlab("MPI Processes") +
ylab("Execution time(s)");
plot(g);
